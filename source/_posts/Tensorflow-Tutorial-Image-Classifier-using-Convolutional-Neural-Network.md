---
title: 'Tensorflow Tutorial: Image Classifier using Convolutional Neural Network'
keywords:
  - xiyusullos
  - aponder
  - 'Tensorflow Tutorial: Image Classifier using Convolutional Neural Network'
date: 2019-04-18 11:09:11
tags:
---

ç¿»è¯‘ï¼š[Tensorflow Tutorial 2: image classifier using convolutional neural network](https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/)

# Tensorflowæ•™ç¨‹ï¼šä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œçš„å›¾åƒåˆ†ç±»å™¨

åœ¨è¿™ä¸ªTensorflowæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Tensorflowæ„å»ºä¸€ä¸ªåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„å›¾åƒåˆ†ç±»å™¨ã€‚å¦‚æœæ‚¨åˆšåˆšå¼€å§‹ä½¿ç”¨Tensorflowï¼Œé‚£ä¹ˆæœ€å¥½[é˜…è¯»è¿™é‡Œçš„TensorflowåŸºæœ¬æ•™ç¨‹](https://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/tensorflow/tensorflow-tutorial/)ã€‚

ä¸ºäº†æ¼”ç¤ºå¦‚ä½•æ„å»ºåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„å›¾åƒåˆ†ç±»å™¨ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª6å±‚ç¥ç»ç½‘ç»œæ¥è¯†åˆ«å’Œåˆ†ç¦»ç‹—å’ŒçŒ«çš„å›¾åƒã€‚æˆ‘ä»¬å°†è¦æ„å»ºçš„è¿™ä¸ªç½‘ç»œæ˜¯ä¸€ä¸ªéå¸¸å°çš„ç½‘ç»œï¼Œå¯ä»¥åœ¨CPUä¸Šè¿è¡Œå®ƒã€‚ä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œåœ¨å›¾åƒåˆ†ç±»ä¸­æœ‰è¾ƒå¤šçš„å‚æ•°ï¼Œå¦‚æœåœ¨CPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¼šèŠ±è´¹å¤§é‡çš„æ—¶é—´ã€‚ç„¶è€Œï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘æ˜¯å‘æ‚¨å±•ç¤ºçš„æ˜¯å¦‚ä½•ä½¿ç”¨Tensorflowè€Œä¸æ˜¯å‚ä¸[ILSVRC](http://image-net.org/challenges/LSVRC/)æ¥æ„å»ºä¸€ä¸ªçœŸå®çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚åœ¨å¼€å§‹å­¦ä¹ Tensorflowæ•™ç¨‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆä»‹ç»ä¸€ä¸‹å·ç§¯ç¥ç»ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†ã€‚å¦‚æœæ‚¨å·²ç»ç†Ÿæ‚‰å·ç§¯ç¥ç»ç½‘ï¼ˆconv-netsï¼‰ï¼Œæ‚¨å¯ä»¥è½¬åˆ°ç¬¬2éƒ¨åˆ†ï¼Œå³Tensorflowæ•™ç¨‹ã€‚

<!-- more -->

## ç¬¬1éƒ¨åˆ†ï¼šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åŸºç¡€

ç¥ç»ç½‘ç»œæœ¬è´¨ä¸Šæ˜¯æ±‚è§£ä¼˜åŒ–é—®é¢˜çš„æ•°å­¦æ¨¡å‹ã€‚å®ƒä»¬ç”±ç¥ç»å…ƒæ„æˆï¼Œç¥ç»å…ƒæ˜¯ç¥ç»ç½‘ç»œçš„åŸºæœ¬è®¡ç®—å•å…ƒã€‚ä¸€ä¸ªç¥ç»å…ƒæ¥å—ä¸€ä¸ªè¾“å…¥ï¼ˆæ¯”æ–¹è¯´ï¼š$x$ï¼‰ï¼Œå¯¹å®ƒåšä¸€äº›è®¡ç®—ï¼ˆæ¯”æ–¹è¯´ï¼šç”¨ä¸€ä¸ªå˜é‡$w$ä¹˜ä»¥å®ƒï¼Œå†åŠ ä¸Šå¦ä¸€ä¸ªå˜é‡$b$ï¼‰æ¥äº§ç”Ÿä¸€ä¸ªå€¼ï¼ˆæ¯”æ–¹è¯´ï¼š$z = wx + b$ï¼‰ã€‚è¿™ä¸ªå€¼è¢«ä¼ é€’ç»™ä¸€ä¸ªå«åš**æ¿€æ´»å‡½æ•°fï¼ˆactivation functionï¼‰**çš„éçº¿æ€§å‡½æ•°ï¼Œä»¥äº§ç”Ÿç¥ç»å…ƒçš„æœ€ç»ˆè¾“å‡ºï¼ˆæ¿€æ´»ï¼‰ã€‚æ¿€æ´»å‡½æ•°æœ‰å¾ˆå¤šç§ï¼Œ**Sigmoid**æ˜¯å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ä¹‹ä¸€ï¼Œæ•°å­¦å…¬å¼ä¸ºï¼š
$$
y = \frac{1}{1+e^{-z}}
$$
åˆ©ç”¨sigmoidå‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒç§°ä¸º**Sigmoidç¥ç»å…ƒï¼ˆSigmoid neuronï¼‰**ã€‚æ ¹æ®æ¿€æ´»å‡½æ•°çš„ä¸åŒï¼Œç¥ç»å…ƒå¯è¢«å‘½åä¸º**RELU**ã€**TanH**ç­‰ç¥ç»å…ƒï¼ˆè®°ä½è¿™ä¸€ç‚¹ï¼‰ã€‚ä¸€ä¸ªç¥ç»å…ƒå¯ä»¥è¿æ¥åˆ°å¤šä¸ªç¥ç»å…ƒï¼Œå°±åƒè¿™æ ·ï¼š

![Neuron in Tensorflow tutorial](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/191x118xfigures_ArtificialNeuron.png)

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°**æƒå€¼**ï¼ˆweightï¼‰æ˜¯è¿æ¥ï¼ˆconnectionï¼‰çš„å±æ€§ï¼Œå³æ¯ä¸ªè¿æ¥éƒ½æœ‰ä¸åŒçš„æƒå€¼ï¼Œè€Œ**åå·®**ï¼ˆbiasï¼‰æ˜¯ç¥ç»å…ƒçš„å±æ€§ã€‚è¿™æ˜¯äº§ç”Ÿè¾“å‡ºyçš„sigmoidç¥ç»å…ƒçš„å…¨å›¾ï¼š
$$
z = b + \sum_{i}x_iw_i \\
y = \frac{1}{1+e^{-z}}
$$

### ç¥ç»å±‚

å¦‚æœä½ æŠŠç¥ç»å…ƒå †åœ¨ä¸€æ¡ç›´çº¿ä¸Šï¼Œè¿™å«åšä¸€å±‚ã€‚è¿™æ˜¯ç¥ç»ç½‘ç»œçš„ä¸‹ä¸€ä¸ªç»„æˆéƒ¨åˆ†ã€‚


  ![neural network shown in Tensorflow tutorial ](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/nnet.png)

å¦‚ä¸Šæ‰€ç¤ºï¼Œ

- è¾“å…¥å±‚ï¼šç»¿è‰²çš„ç¥ç»å…ƒæ„æˆäº†ç½‘ç»œçš„ç¬¬ä¸€å±‚ï¼Œè¾“å…¥æ•°æ®é€šè¿‡ç¬¬ä¸€å±‚ä¼ é€’åˆ°ç½‘ç»œã€‚

- è¾“å‡ºå±‚ï¼šå¦‚çº¢è‰²æ‰€ç¤ºã€‚

- éšè—å±‚ï¼šåœ¨è¾“å…¥å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´çš„å±‚ç§°ä¸ºéšè—å±‚ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªç”¨è“è‰²è¡¨ç¤ºçš„éšè—å±‚ã€‚å…·æœ‰è®¸å¤šéšå«å±‚çš„ç½‘ç»œå¾€å¾€æ›´ç²¾ç¡®ï¼Œç§°ä¸º**æ·±åº¦ç½‘ç»œ**ã€‚è€Œä½¿ç”¨è¿™äº›æ·±åº¦ç½‘ç»œçš„æœºå™¨å­¦ä¹ ç®—æ³•ç§°ä¸º**æ·±åº¦å­¦ä¹ **ã€‚

### ç¥ç»å±‚çš„ç±»å‹

é€šå¸¸ï¼Œä¸€å±‚ä¸­çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½è¿›è¡Œç±»ä¼¼çš„æ•°å­¦è¿ç®—ï¼Œè¿™å°±æ˜¯è¯¥å±‚åç§°çš„ç”±æ¥ï¼ˆè¾“å…¥å±‚å’Œè¾“å‡ºå±‚é™¤å¤–ï¼Œå› ä¸ºå®ƒä»¬å¾ˆå°‘è¿›è¡Œæ•°å­¦è¿ç®—ï¼‰ã€‚ä»¥ä¸‹æ˜¯ä½ åº”è¯¥çŸ¥é“çš„æœ€æµè¡Œçš„ç¥ç»å±‚ç±»å‹ï¼š

#### å·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰

å·ç§¯æ˜¯ä¸€ç§æ•°å­¦è¿ç®—ï¼Œç”¨äºå•æ¬¡å¤„ç†ä¸­å¯¹ä¿¡å·è¿›è¡Œæ»¤æ³¢ï¼Œå¯»æ‰¾ä¿¡å·ä¸­çš„æ¨¡å¼ç­‰ã€‚åœ¨å·ç§¯å±‚ä¸­ï¼Œæ‰€æœ‰çš„ç¥ç»å…ƒéƒ½å¯¹è¾“å…¥è¿›è¡Œå·ç§¯è¿ç®—ï¼Œå› æ­¤ç§°ä¸ºå·ç§¯ç¥ç»å…ƒã€‚å·ç§¯ç¥ç»å…ƒä¸­æœ€é‡è¦çš„å‚æ•°æ˜¯è¿‡æ»¤å™¨ï¼ˆfilterï¼‰çš„å¤§å°ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè¿‡æ»¤å™¨å¤§å°ä¸º5\*5\*3çš„å±‚ã€‚åŒæ ·ï¼Œå‡è®¾è¾“å…¥åˆ°å·ç§¯ç¥ç»å…ƒçš„æ˜¯ä¸€ä¸ªå¤§å°ä¸º32\*32çš„è¾“å…¥å›¾åƒï¼Œæœ‰3ä¸ªé€šé“ï¼ˆå³Rã€Gã€Bï¼‰ã€‚

![Convolution in Tensorflow tutorial](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/289x273xConvolution.png)

è®©æˆ‘ä»¬ä»å›¾åƒä¸­é€‰æ‹©ä¸€ä¸ª5\*5\*3ï¼ˆå½©è‰²å›¾åƒä¸­æœ‰3ä¸ªé€šé“ï¼‰å¤§å°çš„å—ï¼Œç„¶åç”¨è¿‡æ»¤å™¨ï¼ˆ$w$ï¼‰è®¡ç®—å·ç§¯ï¼ˆç‚¹ç§¯ï¼‰ã€‚è¿™ä¸ªå·ç§¯è¿ç®—å°†å¾—åˆ°ä¸€ä¸ªæ•°å­—ä½œä¸ºè¾“å‡ºã€‚æˆ‘ä»¬è¿˜å¯ä»¥æŠŠåç½®ï¼ˆ$b$ï¼‰åŠ åˆ°è¿™ä¸ªè¾“å‡ºä¸­ã€‚

![convolution explained during Tensorflow tutorial](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/268x125xconvolve2.png)

ä¸ºäº†è®¡ç®—ç‚¹ç§¯ï¼Œè¿‡æ»¤å™¨çš„ç¬¬ä¸‰ç»´æ•°å¿…é¡»ä¸è¾“å…¥çš„é€šé“æ•°ç›¸åŒã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“æˆ‘ä»¬è®¡ç®—ç‚¹ç§¯æ—¶ï¼Œå®ƒæ˜¯ä¸€ä¸ª5\*5\*3çš„å—ä¸5\*5\*3çš„è¿‡æ»¤å™¨çš„çŸ©é˜µä¹˜æ³•ã€‚

æˆ‘ä»¬å°†åœ¨æ•´ä¸ªè¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨å·ç§¯è¿‡æ»¤å™¨æ¥è®¡ç®—æ•´ä¸ªå›¾åƒçš„è¾“å‡ºï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![Convolution_schematic](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/Convolution_schematic.gif)

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬æ¯æ¬¡å°†çª—å£æ»‘åŠ¨1ä¸ªåƒç´ ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¼šå°†çª—å£æ»‘åŠ¨è¶…è¿‡1ä¸ªåƒç´ ã€‚è¿™ä¸ªæ•°å­—å«åš**æ­¥é•¿ï¼ˆstrideï¼‰**ã€‚

å¦‚æœå°†æ‰€æœ‰è¿™äº›è¾“å‡ºè¿æ¥åˆ°2Dä¸­ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªå¤§å°ä¸º28\*28çš„è¾“å‡º**æ¿€æ´»å›¾ï¼ˆactivation mapï¼‰**ï¼ˆæ‚¨èƒ½æƒ³åˆ°ä¸ºä»€ä¹ˆåœ¨è¿‡æ»¤å™¨ä¸º5\*5ï¼Œæ­¥é•¿ä¸º1æ—¶ï¼Œæ˜¯ä»32\*32åˆ°28\*28ï¼Ÿï¼‰ã€‚å¦‚æœæˆ‘ä»¬çš„ç¤ºä¾‹ä¸­æœ‰6ä¸ªè¿‡æ»¤å™¨ï¼Œé‚£ä¹ˆè¾“å‡ºçš„å¤§å°å°†æ˜¯28\*28\*6ã€‚

![Convolution-Case-Conflict](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/Convolution-Case-Conflict.png)

æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œæ¯æ¬¡å·ç§¯ä¹‹åï¼Œè¾“å‡ºçš„å¤§å°éƒ½ä¼šå‡å°ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»32\*32å‡å°åˆ°28\*28ï¼‰ã€‚åœ¨ä¸€ä¸ªå¤šå±‚çš„æ·±åº¦ç¥ç»ç½‘ç»œä¸­ï¼Œè¿™æ ·çš„è¾“å‡ºä¼šå˜å¾—éå¸¸å°ï¼Œä½†è¿™å¹¶ä¸èƒ½å¾ˆå¥½åœ°å·¥ä½œã€‚å› æ­¤ï¼Œåœ¨è¾“å…¥å±‚çš„è¾¹ç•Œä¸Šè¿›è¡Œ0å¡«å……æ˜¯ä¸€ç§æ ‡å‡†åšæ³•ï¼Œè¿™æ ·è¾“å‡ºçš„å¤§å°å°±ä¸è¾“å…¥å±‚çš„å¤§å°ç›¸åŒã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå¦‚æœæˆ‘ä»¬åœ¨è¾“å…¥å±‚çš„ä¸¤è¾¹éƒ½æ·»åŠ ä¸€ä¸ªå¤§å°ä¸º2çš„å¡«å……ï¼Œé‚£ä¹ˆè¾“å‡ºå±‚çš„å¤§å°å°†æ˜¯32\*32\*6ï¼Œè¿™ä»å®ç°çš„ç›®çš„æ¥çœ‹ä¹Ÿéå¸¸æœ‰ç”¨ã€‚å‡è®¾æ‚¨æœ‰ä¸€ä¸ªå¤§å°ä¸º$N*N$çš„è¾“å…¥ï¼Œè¿‡æ»¤å™¨ï¼ˆfilterï¼‰çš„å€¼ä¸º$F$ï¼Œæ­¥é•¿ï¼ˆstrideï¼‰ä¸º$S$ï¼Œæœ‰$Pâ€‹$ä¸ª0å¡«å……ï¼Œé‚£ä¹ˆè¾“å‡ºå¤§å°ä¸ºï¼š
$$
(N - F + 2P)/S + 1
$$

#### æ± åŒ–å±‚ï¼ˆPooling Layerï¼‰

åœ¨å·ç§¯å±‚ä¹‹åï¼Œå°†æ¥ç€ç”¨æ± åŒ–å±‚ï¼Œä»¥å‡å°ç©ºé—´å¤§å°ï¼ˆåªæœ‰å®½åº¦å’Œé«˜åº¦ï¼Œæ²¡æœ‰æ·±åº¦ï¼‰ã€‚è¿™å‡å°‘äº†å‚æ•°çš„æ•°é‡ï¼Œä»è€Œå‡å°‘äº†è®¡ç®—é‡ã€‚æ­¤å¤–ï¼Œè¾ƒå°‘çš„å‚æ•°é¿å…äº†è¿‡æ‹Ÿåˆï¼ˆoverfitï¼‰ï¼ˆç°åœ¨ä¸ç”¨æ‹…å¿ƒï¼Œç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ã€‚æœ€å¸¸è§çš„æ± çš„å½¢å¼æ˜¯**æœ€å¤§æ± ï¼ˆmax poolingï¼‰**ï¼Œæˆ‘ä»¬å–ä¸€ä¸ªå¤§å°ä¸ºF\*Fçš„è¿‡æ»¤å™¨ï¼Œå¹¶å¯¹å›¾åƒçš„F\*Féƒ¨åˆ†å–å…¶æœ€å¤§å€¼ã€‚

![maxpool](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/300x140xmaxpool.jpg)

å¦‚æœä½ ç”¨å¹³å‡å€¼æ¥ä»£æ›¿æœ€å¤§å€¼ï¼Œå®ƒä¼šè¢«ç§°ä¸º**å¹³å‡æ± ï¼ˆaverage poolingï¼‰**ï¼Œä½†å®ƒä¸æ˜¯å¾ˆæµè¡Œã€‚

å¦‚æœä½ çš„è¾“å…¥å¤§å°ä¸º $w1*h1*d1$ ï¼Œè¿‡æ»¤å™¨çš„å¤§å°ä¸º$f*f$ ï¼Œæ­¥é•¿ä¸º$S$ï¼Œé‚£ä¹ˆè¾“å‡ºå¤§å°ä¸º$w2*h2*d2$ï¼š
$$
w2 = (w1 - f)/S + 1 \\
h2 = (h1 - f)/S + 1 \\
d2 = d1
$$
æœ€å¸¸è§çš„æ± ä½¿ç”¨å¤§å°ä¸º2\*2çš„è¿‡æ»¤å™¨ï¼Œæ­¥é•¿ä¸º2ã€‚æ­£å¦‚æ‚¨å¯ä»¥ä½¿ç”¨ä¸Šé¢çš„å…¬å¼æ¥è®¡ç®—ï¼Œå®ƒå‡å°‘äº†ä¸€åŠçš„è¾“å…¥å¤§å°ã€‚

![Max pooling with filter size of 2*2 during Tensorflow tutorial](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/211x166xpool-1.jpg)

#### å…¨è¿æ¥å±‚ï¼ˆFully Connected Layerï¼‰

å¦‚æœä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½æ¥æ”¶åˆ°ä¸Šä¸€å±‚æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å…¥ï¼Œé‚£ä¹ˆè¿™ä¸€å±‚å°±ç§°ä¸º**å…¨è¿æ¥å±‚ï¼ˆfully connected layerï¼‰**ã€‚è¯¥å±‚çš„è¾“å‡ºç”±çŸ©é˜µä¹˜æ³•å’Œåç½®åç§»é‡è®¡ç®—ã€‚

### ç†è§£è®­ç»ƒè¿‡ç¨‹

æ·±å±‚ç¥ç»ç½‘ç»œåªä¸è¿‡æ˜¯èªæ˜çš„æ•°å­¦æ¨¡å‹ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šæ¨¡æ‹Ÿäº†äººè„‘ã€‚å½“æˆ‘ä»¬è¯•å›¾è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬éœ€è¦åš2ä»¶åŸºæœ¬çš„äº‹æƒ…ï¼š

#### ç½‘ç»œçš„æ¶æ„

å½“è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œçš„æ¶æ„æ—¶ï¼Œä½ å¿…é¡»å†³å®šï¼šå¦‚ä½•å®‰æ’å±‚ï¼Ÿä½¿ç”¨å“ªäº›å±‚ï¼Ÿæ¯ä¸€å±‚ä½¿ç”¨å¤šå°‘ä¸ªç¥ç»å…ƒç­‰ç­‰ï¼Ÿæ¶æ„è®¾è®¡æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤æ‚çš„ã€é«˜éš¾åº¦çš„è¯¾é¢˜ï¼Œéœ€è¦å¤§é‡çš„ç ”ç©¶ã€‚æœ‰è®¸å¤šæ ‡å‡†çš„æ¶æ„å¯ä»¥å¾ˆå¥½åœ°è§£å†³è®¸å¤šæ ‡å‡†é—®é¢˜ã€‚ä¾‹å¦‚AlexNetï¼ŒGoogleNetï¼ŒInceptionResnetï¼ŒVGGç­‰ã€‚åœ¨åˆšå¼€å§‹æ—¶ï¼Œæ‚¨åº”è¯¥åªä½¿ç”¨æ ‡å‡†çš„ç½‘ç»œæ¶æ„ã€‚åœ¨æ‚¨å¯¹ç¥ç»ç½‘ç»œæœ‰äº†å¾ˆå¤šç»éªŒä¹‹åï¼Œæ‚¨å°±å¯ä»¥å¼€å§‹è®¾è®¡è‡ªå·±çš„ç½‘ç»œæ¶æ„äº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸å¿…æ‹…å¿ƒã€‚

#### æ­£ç¡®çš„æƒé‡/å‚æ•°

ä¸€æ—¦æ‚¨å†³å®šäº†ç½‘ç»œçš„æ¶æ„ï¼Œé‚£ä¹ˆï¼Œç¬¬äºŒé‡è¦çš„å°±æ˜¯æƒé‡$w$å’Œåå·®$b$æˆ–ç½‘ç»œå‚æ•°ã€‚**è®­ç»ƒç›®æ ‡**æ˜¯å¾—åˆ°æ‰€æœ‰è¿™äº›å‚æ•°çš„æœ€ä½³å€¼ï¼Œä»è€Œå¯é åœ°è§£å†³é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬æ­£åœ¨åŠªåŠ›æ„å»ºç‹—å’ŒçŒ«ä¹‹é—´çš„åˆ†ç±»å™¨ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°åˆé€‚çš„å‚æ•°ï¼Œåœ¨æ‰€æœ‰å›¾ç‰‡æ˜¯ç‹—çš„æ—¶å€™ç»™å‡ºç‹—çš„æ¦‚ç‡ä¸º1ï¼ˆæˆ–è€…è‡³å°‘é«˜äºçŒ«çš„æ¦‚ç‡ï¼‰æˆ–è€…åœ¨æ‰€æœ‰å›¾ç‰‡æ˜¯çŒ«çš„æ—¶å€™ï¼Œç»™å‡ºçŒ«çš„æ¦‚ç‡ä¸º1ï¼ˆæˆ–è€…è‡³å°‘é«˜äºç‹—çš„æ¦‚ç‡ï¼‰ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä¸€ä¸ªç§°ä¸º**åå‘ä¼ æ’­ï¼ˆBackward propagationï¼‰**çš„è¿‡ç¨‹æ¥æ‰¾åˆ°æœ€ä½³çš„å‚æ•°é›†ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ‚¨ä»ä¸€ä¸ªéšæœºçš„å‚æ•°é›†å¼€å§‹ï¼Œå¹¶ä¸æ–­æ›´æ”¹è¿™äº›æƒé‡ï¼Œç›´åˆ°å¯¹äºæ¯ä¸ªè®­ç»ƒå›¾åƒï¼Œæˆ‘ä»¬éƒ½èƒ½å¾—åˆ°æ­£ç¡®çš„è¾“å‡ºã€‚æœ‰è®¸å¤šä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰å¯ä»¥æ”¹å˜æƒé‡ï¼Œè¿™äº›ä¼˜åŒ–å™¨å¯ä»¥ä»æ•°å­¦è§’åº¦å¿«é€Ÿåœ°æ‰¾åˆ°æ­£ç¡®çš„æƒé‡ã€‚æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰å°±æ˜¯è¿™æ ·ä¸€ç§æ–¹æ³•ï¼ˆåå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ˜¯ä¸€ä¸ªéå¸¸å¤æ‚çš„ä¸»é¢˜ï¼Œä½†æ˜¯æˆ‘ä»¬ç°åœ¨ä¸éœ€è¦æ‹…å¿ƒå®ƒï¼Œå› ä¸ºTensorflowä¼šå¤„ç†å®ƒï¼‰ã€‚

å› æ­¤ï¼Œå‡è®¾æˆ‘ä»¬ä»ä¸€äº›å‚æ•°çš„åˆå€¼å¼€å§‹ï¼Œå¹¶è¾“å…¥1å¼ ç‹—çš„è®­ç»ƒå›¾ç‰‡ï¼ˆå®é™…ä¸Šæ˜¯å¤šå¼ å›¾ç‰‡ä¸€èµ·å–‚é£Ÿï¼ˆfeedï¼‰ï¼‰ï¼Œæˆ‘ä»¬è®¡ç®—ç½‘ç»œçš„è¾“å‡ºä¸ºæ˜¯ç‹—çš„æ¦‚ç‡ä¸º0.1ï¼Œæ˜¯çŒ«çš„æ¦‚ç‡ä¸º0.9ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬åšåå‘ä¼ æ’­æ¥**ç¼“æ…¢åœ°æ”¹å˜**å‚æ•°ï¼Œè¿™æ ·åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œè¿™ä¸ªå›¾ç‰‡æ˜¯ç‹—çš„æ¦‚ç‡å°±ä¼šå¢åŠ ã€‚æœ‰ä¸€ä¸ªå˜é‡æ˜¯ç”¨æ¥æ§åˆ¶æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¹å˜ç½‘ç»œå‚æ•°çš„é€Ÿåº¦ï¼Œå«**å­¦ä¹ ç‡ï¼ˆlearning rateï¼‰**ã€‚å¦‚æœæ‚¨ä»”ç»†æƒ³æƒ³ï¼Œæˆ‘ä»¬åˆ©ç”¨ç½‘ç»œæ¥æœ€å¤§åŒ–æ‰€æœ‰æ­£ç¡®çš„åˆ†ç±»ï¼ˆå³æˆ‘ä»¬å…³å¿ƒæ•´ä¸ªè®­ç»ƒé›†ï¼‰ã€‚æˆ‘ä»¬å¸Œæœ›è¿›è¡Œè¿™äº›æ›´æ”¹ï¼Œä½¿ç½‘ç»œæ­£ç¡®åˆ†ç±»çš„æ•°é‡å¢åŠ ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç§°ä¸º**ä»£ä»·ï¼ˆcostï¼‰**çš„æ•°å­—ï¼Œå®ƒè¡¨ç¤ºè®­ç»ƒæ˜¯å¦åœ¨æ­£ç¡®çš„æ–¹å‘ä¸Šè¿›è¡Œã€‚**é€šå¸¸ï¼Œcostçš„å®šä¹‰æ˜¯è¿™æ ·çš„ï¼šéšç€ä»£ä»·çš„é™ä½ï¼Œç½‘ç»œçš„æ­£ç¡®ç‡å°†æé«˜ã€‚**å› æ­¤ï¼Œæˆ‘ä»¬å…³æ³¨costï¼Œå¹¶ä¸æ–­åœ°è¿›è¡Œæ­£å‘æˆ–åå‘ä¼ æ’­çš„å¤šæ¬¡è¿­ä»£ï¼ˆæœ‰æ—¶10sä¸Šåƒæ¬¡ï¼‰ï¼Œç›´åˆ°coståœæ­¢ä¸‹é™ã€‚costæœ‰å¾ˆå¤šç§å®šä¹‰ï¼Œå…¶ä¸­ä¸€ä¸ªç®€å•çš„æ˜¯**å‡æ–¹æ ¹ä»£ä»·ï¼ˆmean root costï¼‰**ã€‚å‡è®¾$y_{prediction}$æ˜¯å¯¹äºæ‰€æœ‰è®­ç»ƒå›¾åƒç½‘ç»œè¾“å‡ºçš„å‘é‡ï¼ˆvectorï¼‰ï¼Œ$y_{actual}$æ˜¯å¯¹äºè¿™äº›æ ‡è®°å›¾åƒçš„å®é™…å€¼ï¼ˆä¹Ÿå«ground truthï¼‰çš„å‘é‡ã€‚æ‰€ä»¥ï¼Œå¦‚æœæˆ‘ä»¬æœ€å°åŒ–è¿™ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„è·ç¦»ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è®­ç»ƒæŒ‡æ ‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†costå®šä¹‰ä¸ºæ‰€æœ‰å›¾åƒçš„è¿™äº›è·ç¦»çš„å¹³å‡å€¼ï¼š
$$
cost=0.5 \sum_{i=0}^n (y_{actual}-y_{prediction})^2
$$
è¿™æ˜¯costçš„ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ï¼Œä½†æ˜¯åœ¨å®é™…çš„è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ›´å¤æ‚çš„coståº¦é‡ï¼Œæ¯”å¦‚äº¤å‰ç†µä»£ä»·ï¼ˆcross-entropy costï¼‰ã€‚Tensorflowå®ç°äº†å¾ˆå¤šè¿™äº›costï¼Œæ‰€ä»¥æˆ‘ä»¬ç°åœ¨ä¸éœ€è¦æ‹…å¿ƒè¿™äº›costçš„ç»†èŠ‚ã€‚

è®­ç»ƒå®Œæˆåï¼Œè¿™äº›å‚æ•°å’Œæ¶æ„å°†ä¿å­˜åœ¨ä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶ä¸­ï¼ˆç§°ä¸ºæ¨¡å‹ï¼ˆmodelï¼‰ï¼‰ã€‚åœ¨ç”Ÿäº§è®¾ç½®ä¸­ï¼Œå½“æˆ‘ä»¬å¯¹ä¸€ä¸ªæ–°çš„ç‹—/çŒ«å›¾åƒè¿›è¡Œåˆ†ç±»æ—¶ï¼Œæˆ‘ä»¬å°†è¯¥æ¨¡å‹åŠ è½½åˆ°ç›¸åŒçš„ç½‘ç»œæ¶æ„ä¸­ï¼Œå¹¶è®¡ç®—å‡ºæ–°å›¾åƒæ˜¯çŒ«/ç‹—çš„æ¦‚ç‡ã€‚è¿™å«åš**æ¨ç†ï¼ˆinferenceï¼‰**æˆ–**é¢„æµ‹ï¼ˆpredictionï¼‰**ã€‚

ä¸ºäº†è®¡ç®—ç®€å•ï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„è®­ç»ƒæ•°æ®éƒ½åŒæ—¶è¢«è¾“å…¥åˆ°ç½‘ç»œä¸­ã€‚å‡è®¾ï¼Œæˆ‘ä»¬å…±æœ‰1600å¼ å›¾ç‰‡ï¼Œæˆ‘ä»¬æŠŠå®ƒä»¬åˆ†æˆå°æ‰¹ï¼Œæ¯”å¦‚16å¼ æˆ–32å¼ ï¼Œç§°ä¸º**æ‰¹å¤§å°ï¼ˆbatch-sizeï¼‰**ã€‚å› æ­¤ï¼Œå°†éœ€è¦100æˆ–50è½®ï¼ˆè¿­ä»£ï¼‰æ‰èƒ½è·å¾—ç”¨äºè®­ç»ƒçš„å®Œæ•´æ•°æ®ã€‚è¿™è¢«ç§°ä¸ºä¸€ä¸ª**å†å…ƒï¼ˆepochï¼‰**ï¼Œå³åœ¨ä¸€ä¸ªå†å…ƒä¸­ï¼Œç½‘ç»œå¯ä»¥ä¸€æ¬¡çœ‹åˆ°æ‰€æœ‰çš„è®­ç»ƒå›¾åƒã€‚æˆ‘ä»¬è¿˜éœ€è¦åšä¸€äº›å…¶ä»–äº‹æƒ…æ¥æé«˜å‡†ç¡®æ€§ï¼Œä½†æ˜¯æˆ‘ä»¬ç°åœ¨ä¸éœ€è¦æ‹…å¿ƒè¿™äº›äº‹æƒ…ã€‚

## ç¬¬2éƒ¨åˆ†ï¼šTensorflowæ•™ç¨‹->æ„å»ºä¸€ä¸ªåŸºäºå›¾åƒåˆ†ç±»å™¨çš„å°å‹ç¥ç»ç½‘ç»œ

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªæ›´å°ã€æ›´ç®€å•ï¼ˆä¸ç”¨äºè§£å†³å®é™…é—®é¢˜çš„ç½‘ç»œç›¸æ¯”ï¼‰çš„ç½‘ç»œï¼Œå› æ­¤æ‚¨ä¹Ÿå¯ä»¥åœ¨cpuä¸Šè®­ç»ƒå®ƒã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸¤ä¸ªç±»åˆ«ï¼ˆç‹—/çŒ«ï¼‰çš„å›¾åƒéƒ½è¢«è¾“å…¥åˆ°ä¸€ä¸ªå·ç§¯å±‚ï¼Œè¿™ä¸ªå·ç§¯å±‚åé¢è¿˜æœ‰ä¸¤ä¸ªå·ç§¯å±‚ã€‚åœ¨ç»è¿‡å·ç§¯å±‚ä¹‹åï¼Œæˆ‘ä»¬å°†è¾“å‡ºå¹³åŒ–ï¼ˆflattenï¼‰ï¼Œå¹¶åœ¨æœ€åæ·»åŠ ä¸¤ä¸ªå®Œå…¨è¿æ¥å±‚ã€‚ç¬¬äºŒä¸ªå®Œå…¨è¿æ¥å±‚åªæœ‰ä¸¤ä¸ªè¾“å‡ºï¼Œè¡¨ç¤ºå›¾åƒæ˜¯çŒ«æˆ–ç‹—çš„æ¦‚ç‡ã€‚

![Tensorflow tutorial](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/xTensorflow-tutorial-2-1.jpg)

### å…ˆå†³æ¡ä»¶

#### OpenCV

æˆ‘ä»¬ä½¿ç”¨OpenCVè¯»å–çŒ«/ç‹—çš„å›¾åƒï¼Œæ‰€ä»¥ä½ å¿…é¡»å®‰è£…å®ƒã€‚

#### å½¢çŠ¶å‡½æ•°ï¼ˆshape functionï¼‰

å¦‚æœä½ çš„TFä¸­æœ‰å¤šç»´å¼ é‡ï¼Œä½ å¯ä»¥è¿™æ ·åšæ¥å¾—åˆ°å®ƒçš„å½¢çŠ¶ï¼š

```python
a = tf.truncated_normal([16,128,128,3])
sess = tf.Session()
sess.run(tf.initialize_all_variables())
sess.run(tf.shape(a))
```

è¾“å‡ºï¼š`array([ 16, 128, 128,   3], dtype=int32)`

ä½ å¯ä»¥æŠŠå®ƒé‡å¡‘æˆä¸€ä¸ªå½¢çŠ¶ä¸º[16  128\*128\*3]= [16 49152].æ–°çš„äºŒç»´å¼ é‡ã€‚

```python
b=tf.reshape(a,[16,49152])
sess.run(tf.shape(b))
```

è¾“å‡ºï¼š`array([16, 49152], dtype=int32)`

#### Softmax

Softmaxæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒå°†åŒ…å«å®å€¼çš„kç»´å‘é‡$x$è½¬æ¢ä¸º$(0,1)$èŒƒå›´å†…å®å€¼çš„ç›¸åŒå½¢çŠ¶çš„å‘é‡ï¼Œå…¶å’Œä¸º1ã€‚æˆ‘ä»¬å°†æŠŠsoftmaxå‡½æ•°åº”ç”¨åˆ°å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºä¸­ï¼Œä»¥ä¾¿å°†è¾“å‡ºè½¬æ¢ä¸ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚
$$
o(x)_{j}= \frac{e^{x_{i}}}{ \sum_{n=1}^N e^{x_{n}}}    \,\, for  \, j=1â€¦.N
$$


### è·å–è¾“å…¥

æœ¬æ–‡ä½¿ç”¨äº†æ¥è‡ª[Kaggle dataset](https://www.kaggle.com/c/dogs-vs-cats)çš„2000å¼ ç‹—å’ŒçŒ«çš„å›¾ç‰‡ï¼Œä½†æ˜¯æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•nä¸ªåŒ…å«ä¸åŒç±»å‹å¯¹è±¡çš„å›¾ç‰‡æ–‡ä»¶å¤¹ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬å°†è¾“å…¥æ•°æ®åˆ†ä¸º3éƒ¨åˆ†ï¼š

1. **è®­ç»ƒæ•°æ®ï¼ˆtraining dataï¼‰**ï¼šæˆ‘ä»¬å°†ä½¿ç”¨80%å³1600å¼ å›¾åƒè¿›è¡Œè®­ç»ƒã€‚
2. **éªŒè¯æ•°æ®ï¼ˆvalidation dataï¼‰**ï¼š20%çš„å›¾åƒå°†ç”¨äºéªŒè¯ã€‚è¿™äº›å›¾åƒæ˜¯ä»è®­ç»ƒæ•°æ®ä¸­æå–å‡ºæ¥çš„ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç‹¬ç«‹è®¡ç®—ç²¾åº¦ã€‚
3. **æµ‹è¯•é›†ï¼ˆtest setï¼‰**ï¼šç‹¬ç«‹çš„æµ‹è¯•æ•°æ®ï¼Œå…¶ä¸­çº¦æœ‰400å¼ å›¾åƒã€‚æœ‰æ—¶å› ä¸º**è¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰**â€”â€”ç»è¿‡è®­ç»ƒåï¼Œç¥ç»ç½‘ç»œå¼€å§‹å¯¹è®­ç»ƒæ•°æ®ï¼ˆéå¸¸ç›¸ä¼¼çš„å›¾åƒï¼‰éå¸¸å¥½åœ°å·¥ä½œç€ï¼Œå³costå˜å¾—éå¸¸å°ï¼Œä½†å®ƒä»¬ä¸èƒ½å¾ˆå¥½åœ°é€‚åº”å…¶ä»–å›¾åƒã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨è®­ç»ƒç‹—å’ŒçŒ«ä¹‹é—´çš„åˆ†ç±»å™¨ï¼Œä½ ä»ä¸€ä¸ªæ‹æ‘„æ‰€æœ‰ç™½è‰²èƒŒæ™¯å›¾ç‰‡çš„äººé‚£é‡Œå¾—åˆ°è®­ç»ƒæ•°æ®ã€‚æ‚¨çš„ç½‘ç»œå¯èƒ½åœ¨è¿™ä¸ªéªŒè¯æ•°æ®é›†ä¸Šè¿è¡Œå¾—å¾ˆå¥½ï¼Œä½†æ˜¯å¦‚æœæ‚¨è¯•å›¾åœ¨ä¸€ä¸ªèƒŒæ™¯æ··ä¹±çš„å›¾åƒä¸Šè¿è¡Œå®ƒï¼Œé‚£ä¹ˆå¾ˆå¯èƒ½ä¼šå¤±è´¥ã€‚æ‰€ä»¥ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¯•å›¾ä»ä¸€ä¸ªç‹¬ç«‹çš„æºè·å–æˆ‘ä»¬çš„æµ‹è¯•é›†ã€‚

```python
classes = ['dogs', 'cats']
num_classes = len(classes)

train_path = 'training_data'

# validation split
validation_size = 0.2

# batch size
batch_size = 16

data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)
```

datasetæ˜¯æˆ‘åˆ›å»ºçš„ä¸€ä¸ªç±»ï¼Œç”¨äºè¯»å–è¾“å…¥æ•°æ®ã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„pythonä»£ç ï¼Œä»æä¾›çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ–‡ä»¶å¤¹ä¸­è¯»å–å›¾åƒã€‚

æˆ‘ä»¬çš„è®­ç»ƒç›®æ ‡æ˜¯ï¼šåœ¨ç½‘ç»œä¸­æ‰€æœ‰çš„ç¥ç»å…ƒå­¦ä¹ æ­£ç¡®çš„æƒé‡/åå·®å€¼ï¼Œè¿™äº›ç¥ç»å…ƒè´Ÿè´£å¯¹ç‹—å’ŒçŒ«è¿›è¡Œåˆ†ç±»ã€‚è¿™äº›æƒé‡çš„åˆå€¼å¯ä»¥å–ä»»ä½•å€¼ï¼Œä½†å¦‚æœå–æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸ºé›¶ï¼Œæ–¹å·®è¾ƒå°ï¼‰ï¼Œæ•ˆæœä¼šæ›´å¥½ã€‚åˆå§‹åŒ–ç½‘ç»œè¿˜æœ‰å…¶ä»–æ–¹æ³•ï¼Œä½†æ­£æ€åˆ†å¸ƒæ›´ä¸ºæ™®éã€‚è®©æˆ‘ä»¬é€šè¿‡æŒ‡å®šå½¢çŠ¶åˆ›å»ºå‡½æ•°æ¥å¿«é€Ÿåˆå§‹åŒ–æƒé‡ï¼ˆè¯·è®°ä½ï¼Œæˆ‘ä»¬åœ¨[å‰é¢çš„æ–‡ç« ](https://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/tensorflow/tensorflow-tutorial/)ä¸­è®¨è®ºè¿‡`truncated_normal`å‡½æ•°ï¼‰ã€‚

```python
def create_weights(shape):
    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))

def create_biases(size):
    return tf.Variable(tf.constant(0.05, shape=[size]))
```

### åˆ›å»ºç½‘ç»œå±‚

#### åœ¨TensorFlowä¸­å»ºç«‹å·ç§¯å±‚ï¼ˆconvolution layerï¼‰

`tf.nn.conv2d`å‡½æ•°å¯ä»¥ç”¨æ¥æ„å»ºä¸€ä¸ªå·ç§¯å±‚ï¼Œå®ƒæ¥å—ä»¥ä¸‹è¾“å…¥ï¼š

- `input`=ä¸Šä¸€å±‚çš„è¾“å‡º(æ¿€æ´»)ã€‚è¿™åº”è¯¥æ˜¯ä¸€ä¸ª4ç»´å¼ é‡ã€‚é€šå¸¸ï¼Œåœ¨ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä¸­ï¼Œä½ ä¼ é€’nå¼ å¤§å°ä¸ºwidth\*height\*num_channelsçš„å›¾åƒï¼Œç„¶åè¿™ä¸ªå›¾åƒçš„å¤§å°ä¸º`[n, width, height, num_channels]`
- `filter`=å®šä¹‰è¿‡æ»¤å™¨çš„å¯è®­ç»ƒå˜é‡ã€‚æˆ‘ä»¬ä»ä¸€ä¸ªéšæœºæ­£æ€åˆ†å¸ƒå¼€å§‹å­¦ä¹ è¿™äº›æƒé‡ã€‚å®ƒæ˜¯ä¸€ä¸ª4ç»´å¼ é‡ï¼Œå®ƒçš„å½¢çŠ¶æ˜¯ç½‘ç»œæ¶æ„è®¾è®¡çš„ä¸€éƒ¨åˆ†ã€‚å¦‚æœä½ çš„è¿‡æ»¤å™¨å¤§å°ä¸ºfilter_size\*filter_sizeï¼Œå¹¶ä¸”è¾“å…¥çš„å¤§å°æ˜¯num_input_channelsï¼Œå¹¶ä¸”ä½ çš„å½“å‰å±‚ä¸­æœ‰num_filtersä¸ªè¿‡æ»¤å™¨ï¼Œé‚£ä¹ˆ`filter`å°†å…·æœ‰ä»¥ä¸‹å½¢çŠ¶ï¼š`[filter_size, filter_size, num_input_channels, num_filters]`
- `stride`=å®šä¹‰äº†å·ç§¯æ—¶è¿‡æ»¤å™¨çš„æ­¥é•¿ã€‚åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼Œå®ƒéœ€è¦æ˜¯ä¸€ä¸ª>=4çš„å¼ é‡ï¼ˆTensorï¼‰ï¼Œå³`[batch_stride, x_stride, y_stride, depth_stride]`ã€‚batch_strideæ€»ä¸º1ï¼Œå› ä¸ºæ‚¨ä¸æƒ³è·³è¿‡æ‰¹å¤„ç†ä¸­çš„å›¾åƒã€‚x_strideå’Œy_strideåŸºæœ¬ç›¸åŒï¼Œå¯é€‰æ‹©å€¼æ˜¯ç½‘ç»œæ¶æ„è®¾è®¡çš„ä¸€éƒ¨åˆ†ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­å°†å¯¹å®ƒå–1ã€‚depth_strideæ€»æ˜¯è®¾ç½®ä¸º1ï¼Œå› ä¸ºæ‚¨ä¸ä¼šè·³è¿‡æ·±åº¦ã€‚
- `padding`=**SAME**è¡¨ç¤ºè¾“å…¥ä¸º0ï¼Œè¿™æ ·è¾“å‡ºçš„xã€yç»´åº¦ä¸è¾“å…¥ç›¸åŒã€‚

å·ç§¯ä¹‹åï¼Œæˆ‘ä»¬ç»™ç¥ç»å…ƒåŠ ä¸Šåç½®ï¼ˆbiasï¼‰ï¼Œè¿™ä¹Ÿæ˜¯å¯ä»¥å­¦ä¹ çš„/å¯è®­ç»ƒçš„ã€‚æˆ‘ä»¬è¿˜æ˜¯ä»éšæœºæ­£æ€åˆ†å¸ƒå¼€å§‹ï¼Œç„¶ååœ¨è®­ç»ƒä¸­å­¦ä¹ è¿™äº›å€¼ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬é€šè¿‡`tf.nn.max_pool`å‡½æ•°åº”ç”¨æœ€å¤§æ± åŒ–ï¼Œè¯¥å‡½æ•°ä¸conv2då‡½æ•°å…·æœ‰éå¸¸ç›¸ä¼¼çš„å½¢çŠ¶ã€‚

```python
tf.nn.max_pool(value=layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
```

æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨2\*2çš„k_size/filter_sizeï¼Œåœ¨xå’Œyæ–¹å‘ä¸Šçš„æ­¥é•¿éƒ½æ˜¯2ã€‚å¦‚æœä½¿ç”¨å‰é¢æåˆ°çš„å…¬å¼$w2= (w1-f)/S +1;h2=(h1-f)/S +1$ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¾“å‡ºæ°å¥½æ˜¯è¾“å…¥çš„ä¸€åŠã€‚è¿™äº›æ˜¯æœ€å¤§æ± åŒ–æ—¶æœ€å¸¸ç”¨çš„å€¼ã€‚

æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªRELUä½œä¸ºæˆ‘ä»¬çš„æ¿€æ´»å‡½æ•°ï¼Œå®ƒåªæ¥å—max_poolçš„è¾“å‡ºï¼Œé€šè¿‡`tf.nn.relu`æ¥åº”ç”¨RELUã€‚

æ‰€æœ‰è¿™äº›æ“ä½œéƒ½æ˜¯åœ¨ä¸€ä¸ªå·ç§¯å±‚ä¸­å®Œæˆçš„ã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å®šä¹‰ä¸€ä¸ªå®Œæ•´çš„å·ç§¯å±‚ã€‚

```python
def create_convolutional_layer(input,
               num_input_channels, 
               conv_filter_size,        
               num_filters):  
    
    ## We shall define the weights that will be trained using create_weights function.
    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])
    ## We create biases using the create_biases function. These are also trained.
    biases = create_biases(num_filters)

    ## Creating the convolutional layer
    layer = tf.nn.conv2d(input=input,
                     filter=weights,
                     strides=[1, 1, 1, 1],
                     padding='SAME')

    layer += biases

    ## We shall be using max-pooling.  
    layer = tf.nn.max_pool(value=layer,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME')
    ## Output of pooling is fed to Relu which is the activation function for us.
    layer = tf.nn.relu(layer)

    return layer
```

#### å¹³å±‚ï¼ˆFLattening layerï¼‰

å·ç§¯å±‚çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå¤šç»´å¼ é‡ã€‚æˆ‘ä»¬æƒ³æŠŠå®ƒè½¬æ¢æˆä¸€ç»´å¼ é‡ã€‚è¿™æ˜¯åœ¨å¹³å±‚ä¸­å®Œæˆçš„ã€‚æˆ‘ä»¬åªéœ€è¦ä½¿ç”¨`reshape`æ¥åˆ›å»ºä¸€ä¸ªå®šä¹‰å¦‚ä¸‹çš„ä¸€ç»´å¼ é‡ï¼š

```python
def create_flatten_layer(layer):
    layer_shape = layer.get_shape()
    num_features = layer_shape[1:4].num_elements()
    layer = tf.reshape(layer, [-1, num_features])

    return layer
```

#### å…¨è¿æ¥å±‚ï¼ˆFully connected layerï¼‰

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥åˆ›å»ºä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚å’Œå…¶ä»–å±‚ä¸€æ ·ï¼Œæˆ‘ä»¬å°†æƒé‡å’Œåç½®å£°æ˜ä¸ºéšæœºæ­£æ€åˆ†å¸ƒã€‚åœ¨å…¨è¿æ¥å±‚ä¸­ï¼Œæˆ‘ä»¬å–æ‰€æœ‰çš„è¾“å…¥ï¼Œå¯¹å…¶è¿›è¡Œæ ‡å‡†çš„$z=wx+b$è¿ç®—ã€‚æ­¤å¤–ï¼Œæœ‰æ—¶è¿˜éœ€è¦æ·»åŠ ä¸€ä¸ªéçº¿æ€§ï¼ˆRELUï¼‰ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªå…è®¸è°ƒç”¨è€…å‘å±‚æ·»åŠ RELUæ¡ä»¶ã€‚

```python
def create_fc_layer(input,          
             num_inputs,    
             num_outputs,
             use_relu=True):
    
    #Let's define trainable weights and biases.
    weights = create_weights(shape=[num_inputs, num_outputs])
    biases = create_biases(num_outputs)

    layer = tf.matmul(input, weights) + biases
    if use_relu:
        layer = tf.nn.relu(layer)

    return layer
```

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å®šä¹‰å¥½äº†ç½‘ç»œçš„æ„å»ºä»£ç å—ã€‚

#### å ä½ç¬¦ï¼ˆplaceholderï¼‰å’Œè¾“å…¥ï¼ˆinputï¼‰

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ¥ä¿å­˜è¾“å…¥çš„è®­ç»ƒå›¾åƒã€‚æ‰€æœ‰è¾“å…¥çš„å›¾åƒéƒ½åœ¨`dataset.py`æ–‡ä»¶ä¸­è¯»å–ï¼Œå¹¶å°†å¤§å°è°ƒæ•´ä¸º128 x 128 x 3ã€‚è¾“å…¥å ä½ç¬¦`x`çš„å½¢çŠ¶æ˜¯`[None, 128, 128, 3]`ã€‚ç¬¬ä¸€ä¸ªç»´åº¦ä¸ºNoneæ„å‘³ç€å¯ä»¥å‘å®ƒä¼ é€’ä»»æ„æ•°é‡çš„å›¾åƒã€‚åœ¨è¿™ä¸ªç¨‹åºä¸­ï¼Œæˆ‘ä»¬å°†ä»¥æ‰¹å¤§å°ä¸º16æ¥è¾“å…¥å›¾åƒï¼Œå³`[16, 128, 128, 3]`ã€‚ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå ä½ç¬¦`y_true`æ¥å­˜å‚¨é¢„æµ‹å€¼ã€‚å¯¹äºæ¯ä¸ªå›¾åƒï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè¾“å‡ºï¼Œå³æ¯ä¸ªç±»ç±»åˆ«çš„æ¦‚ç‡ï¼ˆç‹—çš„æ¦‚ç‡å’ŒçŒ«çš„æ¦‚ç‡ï¼‰ã€‚å› æ­¤`y_pred`çš„å½¢çŠ¶æ˜¯`[None, 2]`ï¼ˆå¯¹äºæ‰¹å¤§å°ä¸º16çš„æ•°æ®ï¼Œå®ƒå°†æ˜¯`[16, 2]`ï¼‰ã€‚

```python
x = tf.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels], name='x')

y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')
y_true_cls = tf.argmax(y_true, dimension=1)
```

#### ç½‘ç»œè®¾è®¡

æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å‡½æ•°æ¥åˆ›å»ºç½‘ç»œçš„å„ä¸ªå±‚ã€‚

```python
layer_conv1 = create_convolutional_layer(input=x,
               num_input_channels=num_channels,
               conv_filter_size=filter_size_conv1,
               num_filters=num_filters_conv1)

layer_conv2 = create_convolutional_layer(input=layer_conv1,
               num_input_channels=num_filters_conv1,
               conv_filter_size=filter_size_conv2,
               num_filters=num_filters_conv2)

layer_conv3= create_convolutional_layer(input=layer_conv2,
               num_input_channels=num_filters_conv2,
               conv_filter_size=filter_size_conv3,
               num_filters=num_filters_conv3)
          
layer_flat = create_flatten_layer(layer_conv3)

layer_fc1 = create_fc_layer(input=layer_flat,
                     num_inputs=layer_flat.get_shape()[1:4].num_elements(),
                     num_outputs=fc_layer_size,
                     use_relu=True)

layer_fc2 = create_fc_layer(input=layer_fc1,
                     num_inputs=fc_layer_size,
                     num_outputs=num_classes,
                     use_relu=False)
```

#### é¢„æµ‹

å¦‚ä¸Šæ‰€è¿°ï¼Œé€šè¿‡å°†softmaxåº”ç”¨äºå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸Šï¼Œè¿™æ ·å¯ä»¥å¾—åˆ°æ¯ä¸ªç±»çš„æ¦‚ç‡ã€‚

`y_pred = tf.nn.softmax(layer_fc2,name="y_pred")`

`y_pred`åŒ…å«ç€æ¯ä¸ªç±»åˆ«å¯¹æ¯ä¸ªè¾“å…¥å›¾åƒçš„é¢„æµ‹æ¦‚ç‡ã€‚å…·æœ‰è¾ƒé«˜æ¦‚ç‡çš„ç±»åˆ«æ˜¯å¯¹ç½‘ç»œçš„é¢„æµ‹ã€‚

`y_pred_cls = tf.argmax(y_pred, dimension=1)`

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰æœ€å°çš„ä»£ä»·æ¥å–å¾—æƒé‡çš„æœ€ä¼˜å€¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ä»£ä»·ï¼Œå®ƒå°†ä½¿ç”¨Tensorflowçš„`softmax_cross_entropy_with_logits`å‡½æ•°æ¥è®¡ç®—ï¼Œsoftmax_cross_entropy_with_logitsä½¿ç”¨ä¸Šä¸€ä¸ªå…¨è¿æ¥å±‚çš„è¾“å‡ºå’Œå®é™…æ ‡è®°å€¼æ¥è®¡ç®—äº¤å‰ç†µï¼ˆcross_entropyï¼‰ï¼Œå…¶å¹³å‡å€¼å°†æ˜¯ä»£ä»·ã€‚

```python
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,
                                                    labels=y_true)
cost = tf.reduce_mean(cross_entropy)
```

#### æœ€ä¼˜åŒ–

Tensorflowå®ç°äº†å¤§éƒ¨åˆ†æœ€ä¼˜åŒ–ç®—æ³•ã€‚æˆ‘ä»¬å°†ä½¿ç”¨AdamOptimizerè¿›è¡Œæ¢¯åº¦è®¡ç®—å’Œæƒé‡ä¼˜åŒ–ã€‚æˆ‘ä»¬å°†æ˜ç¡®æŒ‡å‡ºï¼Œæˆ‘ä»¬æ­£è¯•å›¾ä»¥0.0001çš„å­¦ä¹ ç‡æ¥æœ€å°åŒ–ä»£ä»·ã€‚

```python
optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)
```

è¯‘æ–‡ï¼šå¦‚æ‚¨æ‰€çŸ¥ï¼Œå¦‚æœæˆ‘ä»¬ä¸ºäº†è®¡ç®—ä»£ä»·å€¼ï¼Œè¦åœ¨`session.run()`ä¸­è¿è¡Œä¼˜åŒ–å™¨æ“ä½œï¼Œåˆ™å¿…é¡»è¿è¡Œæ•´ä¸ªç½‘ç»œï¼Œå¹¶åœ¨`feed_dict`ä¸­ä¼ é€’è®­ç»ƒå›¾åƒï¼ˆè¿™æœ‰æ„ä¹‰å—ï¼Ÿæƒ³æƒ³çœ‹ï¼Œä½ éœ€è¦åœ¨ä»£ç ä¸­ç”¨ä»€ä¹ˆå˜é‡æ¥è®¡ç®—ä»£ä»·å¹¶ä¿æŒä¸Šå‡ï¼‰ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œä»¥æ‰¹å¤§å°ï¼ˆbatch_sizeï¼‰ä¸º16çš„å½¢å¼ä¼ é€’è®­ç»ƒå›¾åƒã€‚

```python
batch_size = 16

x_batch, y_true_batch, _, cls_batch = data.train.next_batch(batch_size)

feed_dict_train = {x: x_batch, y_true: y_true_batch}

session.run(optimizer, feed_dict=feed_dict_tr)
```

å…¶ä¸­`next_batch`æ˜¯`dataset.py`æ–‡ä»¶ä¸­çš„ä¸€ä¸ªç®€å•çš„pythonå‡½æ•°ï¼Œå®ƒè¿”å›æ¥ä¸‹æ¥è¦ä¼ é€’ç»™è®­ç»ƒçš„16å¼ å›¾åƒã€‚ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬å•ç‹¬åœ°å°†éªŒè¯æ‰¹æ¬¡å›¾åƒä¼ é€’ç»™å¦ä¸€ä¸ª`session.run()`è°ƒç”¨ã€‚

```python
x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size)

feed_dict_val = {x: x_valid_batch, y_true: y_valid_batch}

val_loss = session.run(cost, feed_dict=feed_dict_val)
```

æ³¨æ„ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨`session.run()`ä¸­ä¼ é€’ä»£ä»·ï¼Œä½¿ç”¨çš„æ˜¯ä¸€æ‰¹éªŒè¯å›¾åƒï¼Œè€Œä¸æ˜¯è®­ç»ƒå›¾åƒã€‚ä¸ºäº†è®¡ç®—ä»£ä»·ï¼Œæ•´ä¸ªç½‘ç»œï¼ˆ3ä¸ªå·ç§¯+1ä¸ªå¹³åŒ–+2ä¸ªå…¨è¿æ¥å±‚ï¼‰å°†è¢«æ‰§è¡Œå¹¶ç”Ÿæˆ`layer_fc2`ï¼ˆè¿™å°†è¢«è®¡ç®—äº¤å‰ç†µå’Œä»£ä»·ï¼‰ã€‚ç„¶è€Œï¼Œä¸è®­ç»ƒç›¸åï¼Œè¿™æ¬¡ä¼˜åŒ–`optimizer = tf.train.AdamOptimizer(learning_rate=1 - e-4). minimum (cost)`å°†ä¸ä¼šè¢«è¿è¡Œï¼ˆå› ä¸ºæˆ‘ä»¬åªéœ€è¦è®¡ç®—ä»£ä»·ï¼‰ã€‚è¿™å°±æ˜¯æ”¹å˜æ¢¯åº¦å’Œæƒé‡çš„åŸå› ï¼Œå¹¶ä¸”è¯¥è®¡ç®—éå¸¸æ˜‚è´µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çœŸæ ‡ç­¾ï¼ˆy_trueï¼‰å’Œé¢„æµ‹æ ‡ç­¾ï¼ˆy_predï¼‰æ¥è®¡ç®—éªŒè¯é›†çš„å‡†ç¡®åº¦ã€‚

```
correct_prediction = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
```

æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨`session.run()`ä¸­ä¼ é€’`accuracy`å¹¶åœ¨`feed_dict`ä¸­æä¾›éªŒè¯é›†å›¾åƒæ¥è®¡ç®—éªŒè¯é›†çš„å‡†ç¡®åº¦ã€‚

`val_acc = session.run(accuracy, feed_dict=feed_dict_validate)`

åŒæ ·ï¼Œæˆ‘ä»¬ä¹Ÿå¾—åˆ°äº†è®­ç»ƒå›¾åƒçš„å‡†ç¡®åº¦ã€‚

`acc = session.run(accuracy, feed_dict=feed_dict_train)`

ç”±äºä½¿ç”¨è®­ç»ƒå›¾åƒå’Œæ ‡ç­¾è¿›è¡Œè®­ç»ƒï¼Œæ‰€ä»¥ä¸€èˆ¬è®­ç»ƒé›†çš„å‡†ç¡®åº¦è¦é«˜äºéªŒè¯é›†ã€‚æˆ‘ä»¬è®¡ç®—è®­ç»ƒé›†çš„å‡†ç¡®åº¦æ˜¯ä¸ºäº†çŸ¥é“æˆ‘ä»¬æ˜¯åœ¨æœç€æ­£ç¡®çš„æ–¹å‘å‰è¿›ï¼Œå¹¶ä¸”è‡³å°‘æé«˜äº†è®­ç»ƒæ•°æ®é›†çš„å‡†ç¡®åº¦ã€‚åœ¨æ¯ä¸ªå†å…ƒï¼ˆepochï¼‰ä¹‹åï¼Œæˆ‘ä»¬å¾—åˆ°äº†å‡†ç¡®åº¦çš„å…·ä½“æ•°å€¼å¹¶ç”¨Tensorflowä¸­çš„`saver`å¯¹è±¡æ¥ä¿å­˜æ¨¡å‹ã€‚

```python
saver.save(session, 'dogs-cats-model')
```

è¿™æ˜¯å®Œæ•´çš„è®­ç»ƒå‡½æ•°ï¼š

```python
def train(num_iteration):
    global total_iterations
    
    for i in range(total_iterations, total_iterations + num_iteration):
        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(batch_size)
        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(batch_size)
        
        feed_dict_tr = {x: x_batch, y_true: y_true_batch}
        feed_dict_val = {x: x_valid_batch, y_true: y_valid_batch}

        session.run(optimizer, feed_dict=feed_dict_tr)

        if i % int(data.train.num_examples/batch_size) == 0: 
            val_loss = session.run(cost, feed_dict=feed_dict_val)
            epoch = int(i / int(data.train.num_examples/batch_size))    
            
            show_progress(epoch, feed_dict_tr, feed_dict_val, val_loss)
            saver.save(session, 'dogs-cats-model') 

    total_iterations += num_iteration
```

è¯‘æ–‡ï¼šå› ä¸ºè¿™æ˜¯ä¸€ä¸ªçœŸå®çš„ä¾‹å­ï¼Œæ‰€ä»¥è¿™æ®µä»£ç æœ‰ç‚¹é•¿ã€‚é‚£ä¹ˆï¼Œè¯·åˆ°[è¿™é‡Œ](https://github.com/sankit1/cv-tricks.com)å…‹éš†ä»£ç å¹¶è¿è¡Œtrain.pyæ–‡ä»¶æ¥å¼€å§‹è®­ç»ƒã€‚è¿™æ˜¯è¾“å‡ºçš„ç»“æœï¼š

![Tensorflow tutorial using convolutional neural networks](Tensorflow-Tutorial-Image-Classifier-using-Convolutional-Neural-Network/assets/xtraining_example_tensorflow_tutorial.png)

è¿™æ˜¯ä¸€ä¸ªå°å‹çš„ç½‘ç»œï¼Œä¹Ÿå¹¶ä¸æ˜¯æœ€å…ˆè¿›çš„æ–¹å¼å»å»ºç«‹ä¸€ä¸ªå›¾åƒåˆ†ç±»å™¨ï¼Œä½†å®ƒæ˜¯éå¸¸å¥½çš„å­¦ä¹ ä¾‹å­ï¼Œç‰¹åˆ«æ˜¯å½“ä½ åˆšåˆšå¼€å§‹ã€‚åœ¨æˆ‘ä»¬çš„è®­ç»ƒä¸­ï¼ŒéªŒè¯é›†ä¸Šæœ‰80%ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚ç”±äºæˆ‘ä»¬åœ¨è®­ç»ƒä¸­ä¿å­˜äº†æ¨¡å‹ï¼Œæ¥ä¸‹æ¥å°†ç”¨åœ¨æˆ‘ä»¬è‡ªå·±çš„å›¾åƒä¸Šè¿è¡Œã€‚

### é¢„æµ‹

å½“ä½ è®­ç»ƒå®Œåï¼Œä½ ä¼šæ³¨æ„åˆ°æ–‡ä»¶å¤¹ä¸­æœ‰å¾ˆå¤šæ–°æ–‡ä»¶ï¼š

1. dogs-cats-model.meta
2. dogs-cats-model.data-00000-of-00001
3. dogs-cats-model.index
4. checkpoint

`dogs-cats-model.meta`åŒ…å«äº†å®Œæ•´çš„ç½‘ç»œå›¾ï¼Œç¨åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒé‡æ–°åˆ›å»ºè¯¥å›¾ã€‚æˆ‘ä»¬å°†ä½¿ç”¨Tensorflowæä¾›çš„ä¸€ä¸ª`saver`å¯¹è±¡æ¥å®ç°è¿™ä¸€ç‚¹ã€‚

```python
saver = tf.train.import_meta_graph('flowers-model.meta')
```

`dogs-cats-model.data-00000-of-00001`åŒ…å«äº†ç½‘ç»œçš„è®­ç»ƒæƒé‡ï¼ˆå˜é‡çš„å€¼ï¼‰ã€‚å› æ­¤ï¼Œä¸€æ—¦æˆ‘ä»¬é‡æ–°åˆ›å»ºäº†å›¾ï¼Œæˆ‘ä»¬ç”±æ­¤æ¢å¤æƒé‡ã€‚

```python
saver.restore(sess, tf.train.latest_checkpoint('./'))
```

ä¸ºäº†å¾—åˆ°ç½‘ç»œçš„é¢„æµ‹å€¼ï¼Œæˆ‘ä»¬éœ€è¦åƒè®­ç»ƒä¸€æ ·å¯¹è¾“å…¥å›¾åƒè¿›è¡Œè¯»å–å’Œé¢„å¤„ç†ï¼Œåœ¨è®¡ç®—å›¾ä¸Šè·å–`y_pred`ï¼Œå¹¶åœ¨`feed_dict`ä¸­ä¼ é€’æ–°çš„å›¾åƒã€‚å¦‚ä¸‹æ‰€åšï¼š

```python
image = cv2.imread(filename)
# Resizing the image to our desired size and
# preprocessing will be done exactly as done during training
image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)
images.append(image)
images = np.array(images, dtype=np.uint8)
images = images.astype('float32')
images = np.multiply(images, 1.0/255.0) 
#The input to the network is of shape [None image_size image_size num_channels]. Hence we reshape.
x_batch = images.reshape(1, image_size,image_size,num_channels)


graph = tf.get_default_graph()

y_pred = graph.get_tensor_by_name("y_pred:0")

## Let's feed the images to the input placeholders
x= graph.get_tensor_by_name("x:0") 
y_true = graph.get_tensor_by_name("y_true:0") 
y_test_images = np.zeros((1, 2)) 

feed_dict_testing = {x: x_batch, y_true: y_test_images}
result=sess.run(y_pred, feed_dict=feed_dict_testing)
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥è¿è¡Œè¯¥è„šæœ¬æ¥å¯¹ä¸€ä¸ªæ–°çš„ç‹—/çŒ«å›¾åƒè¿›è¡Œé¢„æµ‹ã€‚

```python
python predict.py test_dog.jpg
[[ 0.99398661 Â 0.00601341]]
```

è¾“å‡ºåŒ…å«äº†è¾“å…¥å›¾åƒä¸ºç‹—æˆ–çŒ«çš„æ¦‚ç‡ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç‹—çš„æ¦‚ç‡æ¯”çŒ«é«˜ã€‚

æ­å–œä½ ï¼æ‚¨å·²ç»å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¥æ„å»ºå’Œè®­ç»ƒå›¾åƒåˆ†ç±»å™¨ã€‚

è®­ç»ƒå¥½çš„æ¨¡å‹å’Œæ•°æ®ï¼šåœ¨gitå­˜å‚¨åº“ä¸­ï¼Œæˆ‘åªä¸ºæ¯ä¸ªç±»åˆ«æ·»åŠ äº†500ä¸ªå›¾åƒã€‚ä½†æ˜¯ï¼Œå³ä½¿è®­ç»ƒä¸€ä¸ªåƒæ ·çš„åˆ†ç±»å™¨ï¼Œä¹Ÿéœ€è¦500å¤šå¼ ç‹—/çŒ«çš„å›¾ç‰‡ã€‚æ‰€ä»¥ï¼Œæˆ‘å¯¹è¿™ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªç±»åˆ«ä¸Šè®­ç»ƒäº†2400å¼ å›¾ç‰‡ã€‚ä½ å¯ä»¥ä»è¿™é‡Œä¸‹è½½è¿™äº›å›¾ç‰‡ã€‚è¿™ä¸ªå°å‹çš„cat-dog-datasetæ˜¯Kaggle Dog-Catæ•°æ®é›†çš„å­é›†ï¼Œä¸å½’æˆ‘ä»¬æ‰€æœ‰ã€‚ä½ è¿˜å¯ä»¥ä½¿ç”¨æˆ‘è¿™é‡Œæä¾›çš„[è®­ç»ƒå¥½çš„æ¨¡å‹](https://drive.google.com/open?id=0B2L-gJqoC67Tb3h5WUw2djVuSVk)æ¥ç”Ÿæˆé¢„æµ‹å€¼ã€‚

å®Œæ•´çš„ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/sankit1/cv-tricks.com)æ‰¾åˆ°ã€‚è¯·åœ¨ä¸‹é¢çš„è¯„è®ºä¸­å‘Šè¯‰æˆ‘ä½ çš„é—®é¢˜å’Œåé¦ˆã€‚è¿™äº›è¯„è®ºå’Œåé¦ˆæ˜¯æˆ‘åˆ›åšæ›´å¤šæ•™ç¨‹çš„åŠ¨åŠ›ğŸ™‚ã€‚